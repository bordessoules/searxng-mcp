# Docling Document Parser Service
# Usage: docker-compose up -d
# Access: http://localhost:8001
#
# This runs Docling as a service that the MCP gateway can call.
# VLM processing is done via external API (e.g., Qwen3-VL-8B on LM Studio).

services:
  docling:
    image: python:3.12-slim
    container_name: docling-service
    ports:
      - "8001:8001"
    volumes:
      - ./app:/app
      - docling-cache:/root/.cache/docling
    working_dir: /app
    environment:
      # External VLM API for document understanding (master via Tailscale)
      - VLM_API_URL=${VLM_API_URL:-http://master.tail5bb17d.ts.net:1234/v1}
      - VLM_MODEL=${VLM_MODEL:-qwen/qwen3-vl-4b}
    command: ["bash", "-c", "apt-get update && apt-get install -y --no-install-recommends libxcb1 libx11-6 libxext6 libxrender1 libglib2.0-0 libgl1 libsm6 libice6 && rm -rf /var/lib/apt/lists/* && pip install --no-cache-dir docling uvicorn fastapi httpx && python server.py"]
    restart: unless-stopped

volumes:
  docling-cache:
